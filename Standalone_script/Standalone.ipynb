{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6bebe7c-b28c-42e7-bef2-4bc0f2081a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "import webbrowser\n",
    "\n",
    "import folium\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from branca.element import Template, MacroElement\n",
    "from win32api import MessageBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2514ec1f-573a-4990-b9da-3abdcc28a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path of input csv:  :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing input csv, please wait...\n",
      "Some error occurred, please check mentioned error log file: log/app.log\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter to exit :\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initializing the parameters from the Standalone_config.json (config) file\n",
    "    input_csv_pth = input(\"Path of input csv: \")\n",
    "    cnfg = json.load(open(\"Standalone_config.json\"))\n",
    "    x_columns = cnfg[\"x_columns\"]\n",
    "    model_path = cnfg[\"model_path\"]\n",
    "    save_path = cnfg[\"save_path\"]\n",
    "    y_colmn_predctd = cnfg[\"y_colmn_predctd\"]\n",
    "    labels = cnfg[\"labels\"]\n",
    "    err_log_pth = cnfg[\"err_log_pth\"]\n",
    "    err_log_format = cnfg[\"err_log_format\"]\n",
    "    fpi_thres = cnfg[\"fpi_thres\"]\n",
    "    pred_thrs_low, pred_thrs_high = cnfg[\"pred_thrs_range\"]\n",
    "    json_green = cnfg['json_green']\n",
    "    json_yellow = cnfg['json_yellow']\n",
    "    json_red = cnfg['json_red']\n",
    "    tiles = cnfg['tiles']\n",
    "    map_popup_fields = cnfg['map_popup_fields']\n",
    "    map_popup_fields_alias = cnfg['map_popup_fields_alias']\n",
    "    map_save_path = cnfg['map_save_path']\n",
    "    legend_template_path = cnfg['legend_template_path']\n",
    "\n",
    "    logging.basicConfig(filename=err_log_pth, filemode='a+', format=err_log_format)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    logger.info(\"Starting application\")\n",
    "    print(\"Analysing input csv, please wait...\")\n",
    "    predict_values()\n",
    "    print(\"Model successfully executed\")\n",
    "    logger.info(\"Displaying Categorical graph\")\n",
    "    show_categorical_data()\n",
    "\n",
    "    if MessageBox(None, \"Do you want to generate Map from the predicted result?\", \"Confirmation\", 1) == 1:\n",
    "        print(\"Generating Map...\")\n",
    "        generate_map()\n",
    "        webbrowser.open('file://' + os.path.realpath(map_save_path))\n",
    "\n",
    "except:\n",
    "    logger.error(traceback.format_exc())\n",
    "    print(f\"Some error occurred, please check mentioned error log file: {err_log_pth}\")\n",
    "finally:\n",
    "    input(\"\\nPress Enter to exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b1f317-75bf-44ba-a600-b434684ba9b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10972/741635171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \"\"\"\n\u001b[0;32m      3\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcalculate\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mColumns\u001b[0m \u001b[0mlike\u001b[0m \u001b[0mWindThreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGustTheshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metc\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0madded\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcalculations\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprepared\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mThresholds\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mremoved\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def prepare_test_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function to calculate the new columns from the provided data in the form of pandas dataframe.\n",
    "    Columns like WindThreshold, GustTheshold, etc will be added based on the calculations and dataframe will be\n",
    "    prepared for the model. Thresholds column will be removed from the dataframe.\n",
    "\n",
    "    :param data: Dataframe to used to add and remove columns.\n",
    "    :type data: dataframe\n",
    "    :return: Updated dataframe ready to be used for model\n",
    "    :rtype: dataframe\n",
    "    \"\"\"\n",
    "    data[[\"WindThreshold\", \"GustTheshold\"]] = data.Thresholds.str.split('/', expand=True)\n",
    "    data[\"WindThreshold\"] = data[\"WindThreshold\"].astype(float)\n",
    "    data[\"GustTheshold\"] = data[\"GustTheshold\"].astype(float)\n",
    "    data = data[data[\"WindThreshold\"] > 0][data[\"GustTheshold\"] > 0]\n",
    "    data[\"closeToWindThreshold\"] = round((data[\"WindSustained\"] * 100) / data[\"WindThreshold\"].astype(float), 2)\n",
    "    data[\"closeToGustThreshold\"] = round((data[\"GustSustained\"] * 100) / data[\"GustTheshold\"].astype(float), 2)\n",
    "\n",
    "    data[\"eFPI\"] = data[\"FPI\"].apply(lambda x: round(x / fpi_thres, 2))\n",
    "    data[\"eThres\"] = round(data[\"WindSustained\"] / data[\"WindThreshold\"], 2)\n",
    "    data[\"eThres\"] = np.where(round(data[\"GustSustained\"] / data[\"GustTheshold\"], 2) > data[\"eThres\"],\n",
    "                              round(data[\"GustSustained\"] / data[\"GustTheshold\"], 2), data[\"eThres\"])\n",
    "\n",
    "    data.drop([\"Thresholds\"], axis=1, inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fnc_category(x: int) -> str:\n",
    "    \"\"\"\n",
    "    A function to return the category of the provided threshold value.\n",
    "    Currently divide into 3 categories.\n",
    "\n",
    "    :param x: Value of the threshold to be divide into categorical value\n",
    "    :type x: int\n",
    "    :return: Returned value of category of the provided threshold\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if x > pred_thrs_high:\n",
    "        return \"C\"\n",
    "    elif pred_thrs_high >= x > pred_thrs_low:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "\n",
    "\n",
    "def highlight_cell_excel(s: pd.core.series.Series) -> list:\n",
    "    \"\"\"\n",
    "    A function to add the cell background color based on the predicted column value\n",
    "\n",
    "    :param s: Series to be used for the background color\n",
    "    :type s: int\n",
    "    :return: Returned value of the color coding of the row in the form of list\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "\n",
    "    is_max = pd.Series(data=False, index=s.index)\n",
    "    is_max[y_colmn_predctd] = s.loc[y_colmn_predctd] > pred_thrs_high\n",
    "    if is_max.any():\n",
    "        return ['background-color: #FF0000' for v in is_max]\n",
    "    is_max[y_colmn_predctd] = s.loc[y_colmn_predctd] > pred_thrs_low\n",
    "    if is_max.any():\n",
    "        return ['background-color: #FFFF00' for v in is_max]\n",
    "    else:\n",
    "        return ['background-color: #00FF00' for v in is_max]\n",
    "\n",
    "\n",
    "def predict_values():\n",
    "    \"\"\"\n",
    "    A function to predict the values of the provided csv by the user. It will save the csv in the folder mentioned\n",
    "    in the config file.\n",
    "    \"\"\"\n",
    "    main_df = pd.read_csv(input_csv_pth)\n",
    "    if main_df.empty:\n",
    "        print('Dataset is empty!')\n",
    "        raise (\"Empty input dataset\")\n",
    "    save_excel_path = f\"{save_path[:-3]}xlsx\"\n",
    "    logger.info(\"Preparing data for the prediction\")\n",
    "    test_df_raw = prepare_test_data(main_df)\n",
    "    test_df = test_df_raw[x_columns]\n",
    "    logger.info(\"Prediction dataset prepared\")\n",
    "\n",
    "    logger.info(f\"Loading model from the mentioned pkl file path: {model_path}\")\n",
    "    modll = joblib.load(model_path)\n",
    "    logger.info(\"Predicting values for the input dateset\")\n",
    "    y_predctd = modll.predict(test_df)\n",
    "    logger.info(\"Prediction completed\")\n",
    "    y_predctd = pd.DataFrame(y_predctd, columns=[y_colmn_predctd])\n",
    "    ds = pd.concat([test_df_raw, y_predctd], axis=1)\n",
    "    ds[y_colmn_predctd] = round(ds[y_colmn_predctd] * 100, 2)\n",
    "\n",
    "    ds.to_csv(save_path, index=False)\n",
    "    print(f\"CSV Report generated at: {save_path}\")\n",
    "    # ds = ds.sort_values(by=[y_colmn_predctd], ascending=False)\n",
    "    print(\"Generating Excel report...\")\n",
    "    ds.style.apply(highlight_cell_excel, axis=1).to_excel(save_excel_path, engine='xlsxwriter', index=False)\n",
    "    logger.info(f\"File saved to mentioned path:\\nCSV path: {save_path}\\nExcel path: {save_excel_path}\")\n",
    "    print(f\"Excel Report generated at: {save_excel_path}\")\n",
    "\n",
    "\n",
    "def show_categorical_data():\n",
    "    \"\"\"\n",
    "    A function to display the number of High, Medium, Low risk points over the graph.\n",
    "    \"\"\"\n",
    "    logger.info(\"Reading CSV\")\n",
    "    fire_grp = pd.read_csv(save_path)\n",
    "\n",
    "    msg = f\"{y_colmn_predctd} Range:\\nHigh (RED): {y_colmn_predctd} > {pred_thrs_high}\" \\\n",
    "          f\"\\nMedium (YELLOW): {pred_thrs_high} >= {y_colmn_predctd} > {pred_thrs_low}\\n\" \\\n",
    "          f\"Low (GREEN): {y_colmn_predctd}<={pred_thrs_low}\"\n",
    "\n",
    "    logger.info(msg)\n",
    "    fire_grp[\"pspsGRP\"] = fire_grp[y_colmn_predctd].apply(lambda x: fnc_category(x))\n",
    "    month = fire_grp.groupby(['pspsGRP']).size().reset_index(name='count')[::-1].sort_values('pspsGRP')\n",
    "\n",
    "    values = month['count'].tolist()\n",
    "    if len(values) < 3:\n",
    "        values += [0] * (3 - len(values))\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    plt.ylabel('Predicted Incidents', size=15)\n",
    "    plt.xlabel('Severity', size=15)\n",
    "    plt.bar(labels, values, color=['green', 'yellow', 'red'])\n",
    "    xlocs = [0, 1, 2]\n",
    "    for i, v in enumerate(month['count']): plt.text(xlocs[i] - 0.05, v + 5, str(v))\n",
    "\n",
    "    colors = {'High (Probability>85)': 'red', 'Medium (85>=Probability>60)': 'yellow', 'Low (Probability<=60)': 'green'}\n",
    "    labelsss = list(colors.keys())\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=colors[labelllll]) for labelllll in labelsss]\n",
    "    plt.legend(handles, labelsss)\n",
    "    print(msg)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_map():\n",
    "    \"\"\"\n",
    "    A fucntion to generate map from the predicted report\n",
    "    \"\"\"\n",
    "    map_dta = pd.read_csv(save_path)\n",
    "    map_dta['Circuit'] = map_dta['Circuit'].str.upper().str.strip()\n",
    "    geom_dct = json.load(open(\"json\\circuit_geom.json\", 'r'))\n",
    "    idx = map_dta.groupby(['Circuit'])[y_colmn_predctd].transform(max) == map_dta[y_colmn_predctd]\n",
    "    map_dta = map_dta[idx].reset_index(drop=True)\n",
    "\n",
    "    def categorize_dta(flnm, dtaaaaa):\n",
    "        circuit_dct = {}\n",
    "        lst = []\n",
    "        for index, row in dtaaaaa.iterrows(): circuit_dct[row['Circuit']] = row.to_dict()\n",
    "        for i in geom_dct['features']:\n",
    "            tmp = circuit_dct.get(i[\"properties\"][\"CIRCUIT_NAME\"].upper(), -99)\n",
    "            if (tmp != -99):\n",
    "                i[\"properties\"][\"FPI\"] = tmp[\"FPI\"]\n",
    "                i[\"properties\"][\"WindSustained\"] = tmp[\"WindSustained\"]\n",
    "                i[\"properties\"][\"GustSustained\"] = tmp[\"GustSustained\"]\n",
    "                i[\"properties\"][\"WindThreshold\"] = tmp[\"WindThreshold\"]\n",
    "                i[\"properties\"][\"GustTheshold\"] = tmp[\"GustTheshold\"]\n",
    "                i[\"properties\"][\"PSPS_Activation_probability%\"] = tmp[\"PSPS_Activation_probability%\"]\n",
    "                lst += [i]\n",
    "        dct = {\"type\": \"FeatureCollection\", \"features\": lst}\n",
    "        json.dump(dct, open(flnm, 'w'))\n",
    "\n",
    "    green_dta = map_dta[60 >= map_dta['PSPS_Activation_probability%']]\n",
    "    orange_dta = map_dta[\n",
    "        (85 >= map_dta['PSPS_Activation_probability%']) & (map_dta['PSPS_Activation_probability%'] > 60)]\n",
    "    red_dta = map_dta[map_dta['PSPS_Activation_probability%'] > 85]\n",
    "    categorize_dta(json_green, green_dta)\n",
    "    categorize_dta(json_yellow, orange_dta)\n",
    "    categorize_dta(json_red, red_dta)\n",
    "    m = folium.Map(\n",
    "        location=[34.39, -118.55],\n",
    "        tiles=\"cartodbpositron\",\n",
    "        zoom_start=10,\n",
    "    )\n",
    "\n",
    "    for tile in tiles: folium.TileLayer(tile).add_to(m)\n",
    "\n",
    "    folium.GeoJson(json_green, name=\"Low (Probability<=60)\",\n",
    "                   style_function=lambda x: {'color': 'green', 'highlight': 'True',\n",
    "                                             'line_weight': 2},\n",
    "                   popup=folium.GeoJsonPopup(fields=map_popup_fields, aliases=map_popup_fields_alias)).add_to(m)\n",
    "\n",
    "    folium.GeoJson(json_yellow, name=\"Medium (85>=Probability>60)\", style_function=lambda x: {'color': 'yellow',\n",
    "                                                                                              'highlight': 'True',\n",
    "                                                                                              'line_weight': 2},\n",
    "                   popup=folium.GeoJsonPopup(fields=map_popup_fields, aliases=map_popup_fields_alias)).add_to(m)\n",
    "\n",
    "    folium.GeoJson(json_red, name=\"High (Probability>85)\", style_function=lambda x: {'color': 'red',\n",
    "                                                                                     'highlight': 'True',\n",
    "                                                                                     'line_weight': 2},\n",
    "                   popup=folium.GeoJsonPopup(fields=map_popup_fields, aliases=map_popup_fields_alias)).add_to(m)\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    macro = MacroElement()\n",
    "    macro._template = Template(open(legend_template_path).read())\n",
    "    m.get_root().add_child(macro)\n",
    "    m.save(map_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
